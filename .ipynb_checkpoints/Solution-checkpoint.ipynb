{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Recurrent Neural Networks (RNNs)\n",
    "\n",
    "## Learning stock embeddings for portfolio optimization using bidirectional RNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent Neural Networks (RNNs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bidirectional Gated Recurrent Units (Bi-GRUs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Bi-GRUs for price movement classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purposes of this assignment, we will focus on training a classifier for 15 stocks from the S&P 500. The goal of our classifier is as follows:\n",
    "We are interested in training a bidirectional RNN model that learns a relationship between news taglines related to the 15 stocks $\\{l_1, \\ldots, l_{15}\\}$ that we have selected and the prices of those stocks. Define $p_i^{(t)}$ to be the price of stock $l_i$ on day $t$. Then, we can formally define our objective as follows:\n",
    "\n",
    "Let $y_i^{(t)} = \\begin{cases} 1 & p_i^{(t)} \\geq p_i^{(t - 1)} \\\\ 0 & p_i^{(t)} < p_i^{(t - 1)} \\end{cases}$. Suppose our dataset $D = \\{N^{(t)}\\}_{t_{in} \\leq t \\leq t_f}$, where $N^{(t)}$ is a collection of all the articles from day $t$ and $t_{in}$ and $t_f$ represent the dates of the earliest and latest articles in our dataset resepctively. Then, we want to learn a mapping $\\hat y_i^{(t)} = f(N^{(t - \\mu)} \\cup \\ldots \\cup N^{(t)})$ such that $\\hat y_i^{(t)}$ accurately predicts $y_i^{(t)}$. More specifically, as is often the case with classification problems, we want to minimize the loss function given by the mean cross-entropy loss for all $15$ stocks:\n",
    "$$\\mathcal{L} = \\frac{1}{15} \\sum_{i = 1}^{15} \\mathcal{L}_i = \\frac{1}{15} \\sum_{i = 1}^{15} \\left( \\frac{-1}{t_f - t_{in}} \\sum_{t = t_{in}}^{t_f} \\big(y_i^{(t)} \\log \\hat y_i^{(t)} + (1 - y_i^{(t)}) \\log (1 - \\hat y_i^{(t)}) \\right)$$\n",
    "Here, we choose to use $\\mu = 4$, so we aim to classify the price movement of stock $l_i$ on day $t$, given by $p_i^{(t)}$, using news information from days $[t-4, t]$, i.e., articles $\\{N^{(t - 4)}, N^{(t - 3)}, N^{(t - 2)}, N^{(t - 1)}, N^{(t)}\\}$. Notice that we are including information from day $t$, so we are not *predicting* the price movement but rather identifying a relationship between the stock price movement and the information contained in the news taglines from day $t$ and the previous 4 days."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating word embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below loads word embeddings that we have pre-generated for 15 stocks from the S&P 500. We used news tagline data from Reuters (data sourced from https://github.com/vedic-partap/Event-Driven-Stock-Prediction-using-Deep-Learning/blob/master/input/news_reuters.csv) to create word embeddings for all of the articles in our dataset using a pretrained Spacy encoder and a Word2Vec model that we trained on our data (don't worry if you don't know what this means yet). Our dataset contains news articles from 2011 to 2017 so we should have enough data to build a fairly accurate classifier. You will explore algorithms for generating word embeddings in more detail later in the course but for this assignment, we have done the work for you so that you can focus on building RNN models for your stock movement classifier.\n",
    "\n",
    "For the purposes of our classifier, we are focusing on the 15 stocks from the Reuters dataset for which we have the most data, i.e., news articles.\n",
    "\n",
    "<br>\n",
    "\n",
    "The main idea is to convert all of the qualitative textual information that we have in each article tagline into a quantitative feature that we can use when training our classifier. Let $s_i \\in \\mathbb{R}^{64}$ represent the stock embedding that we are trying to learn for stock $l_i$. We then define the following quantities:\n",
    "\n",
    "Let $n_i^{(t)}$ be a news article from day $t$, for some $1 \\leq i \\leq |N^{(t)}|$. We associate 2 embedding vectors $K_i^{(t)} \\in \\mathbb{R}^{64}$ and $V_i^{(t)} \\in \\mathbb{R}^{300}$ with the article $n_i^{(t)}$, which we have computed for you below. We define $score(n_i^{(t)}, s_j) = K_i^{(t)} \\cdot s_j$ and the softmax variable $$\\alpha_i^{(t)} = \\frac{\\exp(score(n_i^{(t)}, s_j)}{\\sum_{n_k^{(t)} \\in N^{(t)}}exp(score(n_k^{(t)}, s_j))}$$\n",
    "\n",
    "Finally, we define the market status of stock $m_j$ on day $t$, given by $m_j^{(t)} = \\sum_{n_i^{(t)} \\in N^{(t)}} \\alpha_i^{(t)} V_i^{(t)}$. This is the input to the classifier that you will build and train on the dataset to learn the stock embeddings $\\{s_j\\}_{1 \\leq j \\leq 15}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Name</th>\n",
       "      <th>Date</th>\n",
       "      <th>Headline</th>\n",
       "      <th>Tagline</th>\n",
       "      <th>Rating</th>\n",
       "      <th>K0</th>\n",
       "      <th>K1</th>\n",
       "      <th>K2</th>\n",
       "      <th>...</th>\n",
       "      <th>V290</th>\n",
       "      <th>V291</th>\n",
       "      <th>V292</th>\n",
       "      <th>V293</th>\n",
       "      <th>V294</th>\n",
       "      <th>V295</th>\n",
       "      <th>V296</th>\n",
       "      <th>V297</th>\n",
       "      <th>V298</th>\n",
       "      <th>V299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1074</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>1-800 FLOWERSCOM Inc</td>\n",
       "      <td>20140414</td>\n",
       "      <td>Apple antitrust compliance off to a promising ...</td>\n",
       "      <td>NEW YORK Apple Inc has made a \"promising start...</td>\n",
       "      <td>topStory</td>\n",
       "      <td>0.728133</td>\n",
       "      <td>0.074376</td>\n",
       "      <td>-0.844244</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.184006</td>\n",
       "      <td>0.032116</td>\n",
       "      <td>0.032128</td>\n",
       "      <td>-0.045440</td>\n",
       "      <td>0.027079</td>\n",
       "      <td>-0.100620</td>\n",
       "      <td>0.032597</td>\n",
       "      <td>-0.092093</td>\n",
       "      <td>0.048542</td>\n",
       "      <td>0.109286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1075</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>1-800 FLOWERSCOM Inc</td>\n",
       "      <td>20140414</td>\n",
       "      <td>Apple antitrust compliance off to a promising ...</td>\n",
       "      <td>NEW YORK  April 14 Apple Inc has made a \"promi...</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.757790</td>\n",
       "      <td>0.111567</td>\n",
       "      <td>-0.802569</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.168789</td>\n",
       "      <td>0.039603</td>\n",
       "      <td>0.021292</td>\n",
       "      <td>-0.036883</td>\n",
       "      <td>0.029685</td>\n",
       "      <td>-0.110353</td>\n",
       "      <td>0.025347</td>\n",
       "      <td>-0.084554</td>\n",
       "      <td>0.045670</td>\n",
       "      <td>0.105747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1076</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>1-800 FLOWERSCOM Inc</td>\n",
       "      <td>20140414</td>\n",
       "      <td>COLUMN-How to avoid the trouble coming to the ...</td>\n",
       "      <td>(The opinions expressed here are those of the ...</td>\n",
       "      <td>normal</td>\n",
       "      <td>-0.624152</td>\n",
       "      <td>-0.346050</td>\n",
       "      <td>-1.487509</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.141506</td>\n",
       "      <td>-0.027039</td>\n",
       "      <td>-0.080825</td>\n",
       "      <td>-0.133556</td>\n",
       "      <td>0.018669</td>\n",
       "      <td>-0.056828</td>\n",
       "      <td>-0.052640</td>\n",
       "      <td>-0.169819</td>\n",
       "      <td>-0.033054</td>\n",
       "      <td>0.053817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1077</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>1-800 FLOWERSCOM Inc</td>\n",
       "      <td>20140414</td>\n",
       "      <td>How to avoid the trouble coming to the tech se...</td>\n",
       "      <td>CHICAGO A resounding shot across the bow has b...</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.387120</td>\n",
       "      <td>-0.099557</td>\n",
       "      <td>-0.590867</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.233473</td>\n",
       "      <td>0.095700</td>\n",
       "      <td>0.113241</td>\n",
       "      <td>-0.027537</td>\n",
       "      <td>-0.119434</td>\n",
       "      <td>-0.074786</td>\n",
       "      <td>-0.072007</td>\n",
       "      <td>-0.049933</td>\n",
       "      <td>0.014863</td>\n",
       "      <td>0.063664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1078</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>1-800 FLOWERSCOM Inc</td>\n",
       "      <td>20140415</td>\n",
       "      <td>Apple cannot escape U.S. states' e-book antitr...</td>\n",
       "      <td>NEW YORK Apple Inc on Tuesday lost an attempt ...</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.824634</td>\n",
       "      <td>-1.637257</td>\n",
       "      <td>-0.352775</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.232241</td>\n",
       "      <td>0.027836</td>\n",
       "      <td>-0.025965</td>\n",
       "      <td>0.036613</td>\n",
       "      <td>-0.087056</td>\n",
       "      <td>-0.103006</td>\n",
       "      <td>0.076729</td>\n",
       "      <td>-0.153311</td>\n",
       "      <td>0.038894</td>\n",
       "      <td>0.138866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50787</th>\n",
       "      <td>184859</td>\n",
       "      <td>TAPR</td>\n",
       "      <td>Barclays Inverse US Treasury Composite ETN</td>\n",
       "      <td>20170209</td>\n",
       "      <td>BRIEF-Ultra Petroleum says Barclays agreed to ...</td>\n",
       "      <td>* Ultra Petroleum- on Feb 8  in connection wit...</td>\n",
       "      <td>normal</td>\n",
       "      <td>1.139437</td>\n",
       "      <td>0.682006</td>\n",
       "      <td>0.029171</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.244216</td>\n",
       "      <td>0.053853</td>\n",
       "      <td>-0.008725</td>\n",
       "      <td>-0.048169</td>\n",
       "      <td>-0.032766</td>\n",
       "      <td>-0.062842</td>\n",
       "      <td>-0.059161</td>\n",
       "      <td>-0.104091</td>\n",
       "      <td>0.010547</td>\n",
       "      <td>0.129130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50788</th>\n",
       "      <td>184860</td>\n",
       "      <td>TAPR</td>\n",
       "      <td>Barclays Inverse US Treasury Composite ETN</td>\n",
       "      <td>20170209</td>\n",
       "      <td>MOVES-Barclays  Nasdaq  RenCap  AXA  BC Partners</td>\n",
       "      <td>Feb 9 The following financial services industr...</td>\n",
       "      <td>topStory</td>\n",
       "      <td>1.017802</td>\n",
       "      <td>-0.165982</td>\n",
       "      <td>-0.467275</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.234947</td>\n",
       "      <td>0.049924</td>\n",
       "      <td>0.064670</td>\n",
       "      <td>0.022008</td>\n",
       "      <td>0.025572</td>\n",
       "      <td>-0.144732</td>\n",
       "      <td>-0.046366</td>\n",
       "      <td>-0.030195</td>\n",
       "      <td>-0.027131</td>\n",
       "      <td>0.093039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50789</th>\n",
       "      <td>184861</td>\n",
       "      <td>TAPR</td>\n",
       "      <td>Barclays Inverse US Treasury Composite ETN</td>\n",
       "      <td>20170217</td>\n",
       "      <td>Barclays  Citi gave South Africa watchdog info...</td>\n",
       "      <td>JOHANNESBURG  Feb 17 Barclays Plc and Citigrou...</td>\n",
       "      <td>normal</td>\n",
       "      <td>1.044449</td>\n",
       "      <td>-0.042930</td>\n",
       "      <td>0.201579</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.234416</td>\n",
       "      <td>-0.001098</td>\n",
       "      <td>-0.035648</td>\n",
       "      <td>-0.053637</td>\n",
       "      <td>0.030076</td>\n",
       "      <td>-0.037331</td>\n",
       "      <td>0.048593</td>\n",
       "      <td>-0.019262</td>\n",
       "      <td>-0.030251</td>\n",
       "      <td>0.178724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50790</th>\n",
       "      <td>184862</td>\n",
       "      <td>TAPR</td>\n",
       "      <td>Barclays Inverse US Treasury Composite ETN</td>\n",
       "      <td>20170217</td>\n",
       "      <td>Barclays  Citi helped South Africa with forex ...</td>\n",
       "      <td>JOHANNESBURG Barclays Plc  and Citigroup  appr...</td>\n",
       "      <td>topStory</td>\n",
       "      <td>1.288937</td>\n",
       "      <td>-0.372697</td>\n",
       "      <td>0.197727</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.247672</td>\n",
       "      <td>0.049712</td>\n",
       "      <td>0.028656</td>\n",
       "      <td>-0.078167</td>\n",
       "      <td>0.047243</td>\n",
       "      <td>0.061589</td>\n",
       "      <td>0.016127</td>\n",
       "      <td>-0.073754</td>\n",
       "      <td>-0.011532</td>\n",
       "      <td>0.154577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50791</th>\n",
       "      <td>184863</td>\n",
       "      <td>TAPR</td>\n",
       "      <td>Barclays Inverse US Treasury Composite ETN</td>\n",
       "      <td>20170217</td>\n",
       "      <td>UPDATE 1-Barclays  Citi helped South Africa wi...</td>\n",
       "      <td>JOHANNESBURG  Feb 17 Barclays Plc and Citigrou...</td>\n",
       "      <td>normal</td>\n",
       "      <td>1.336899</td>\n",
       "      <td>-0.299033</td>\n",
       "      <td>0.236128</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.244397</td>\n",
       "      <td>0.040046</td>\n",
       "      <td>0.010388</td>\n",
       "      <td>-0.072232</td>\n",
       "      <td>0.047836</td>\n",
       "      <td>0.046529</td>\n",
       "      <td>0.009858</td>\n",
       "      <td>-0.067272</td>\n",
       "      <td>-0.009805</td>\n",
       "      <td>0.183828</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50792 rows × 371 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        index Ticker                                        Name      Date  \\\n",
       "0        1074   AAPL                        1-800 FLOWERSCOM Inc  20140414   \n",
       "1        1075   AAPL                        1-800 FLOWERSCOM Inc  20140414   \n",
       "2        1076   AAPL                        1-800 FLOWERSCOM Inc  20140414   \n",
       "3        1077   AAPL                        1-800 FLOWERSCOM Inc  20140414   \n",
       "4        1078   AAPL                        1-800 FLOWERSCOM Inc  20140415   \n",
       "...       ...    ...                                         ...       ...   \n",
       "50787  184859   TAPR  Barclays Inverse US Treasury Composite ETN  20170209   \n",
       "50788  184860   TAPR  Barclays Inverse US Treasury Composite ETN  20170209   \n",
       "50789  184861   TAPR  Barclays Inverse US Treasury Composite ETN  20170217   \n",
       "50790  184862   TAPR  Barclays Inverse US Treasury Composite ETN  20170217   \n",
       "50791  184863   TAPR  Barclays Inverse US Treasury Composite ETN  20170217   \n",
       "\n",
       "                                                Headline  \\\n",
       "0      Apple antitrust compliance off to a promising ...   \n",
       "1      Apple antitrust compliance off to a promising ...   \n",
       "2      COLUMN-How to avoid the trouble coming to the ...   \n",
       "3      How to avoid the trouble coming to the tech se...   \n",
       "4      Apple cannot escape U.S. states' e-book antitr...   \n",
       "...                                                  ...   \n",
       "50787  BRIEF-Ultra Petroleum says Barclays agreed to ...   \n",
       "50788  MOVES-Barclays  Nasdaq  RenCap  AXA  BC Partners    \n",
       "50789  Barclays  Citi gave South Africa watchdog info...   \n",
       "50790  Barclays  Citi helped South Africa with forex ...   \n",
       "50791  UPDATE 1-Barclays  Citi helped South Africa wi...   \n",
       "\n",
       "                                                 Tagline    Rating        K0  \\\n",
       "0      NEW YORK Apple Inc has made a \"promising start...  topStory  0.728133   \n",
       "1      NEW YORK  April 14 Apple Inc has made a \"promi...    normal  0.757790   \n",
       "2      (The opinions expressed here are those of the ...    normal -0.624152   \n",
       "3      CHICAGO A resounding shot across the bow has b...    normal  0.387120   \n",
       "4      NEW YORK Apple Inc on Tuesday lost an attempt ...    normal  0.824634   \n",
       "...                                                  ...       ...       ...   \n",
       "50787  * Ultra Petroleum- on Feb 8  in connection wit...    normal  1.139437   \n",
       "50788  Feb 9 The following financial services industr...  topStory  1.017802   \n",
       "50789  JOHANNESBURG  Feb 17 Barclays Plc and Citigrou...    normal  1.044449   \n",
       "50790  JOHANNESBURG Barclays Plc  and Citigroup  appr...  topStory  1.288937   \n",
       "50791  JOHANNESBURG  Feb 17 Barclays Plc and Citigrou...    normal  1.336899   \n",
       "\n",
       "             K1        K2  ...      V290      V291      V292      V293  \\\n",
       "0      0.074376 -0.844244  ... -0.184006  0.032116  0.032128 -0.045440   \n",
       "1      0.111567 -0.802569  ... -0.168789  0.039603  0.021292 -0.036883   \n",
       "2     -0.346050 -1.487509  ... -0.141506 -0.027039 -0.080825 -0.133556   \n",
       "3     -0.099557 -0.590867  ... -0.233473  0.095700  0.113241 -0.027537   \n",
       "4     -1.637257 -0.352775  ... -0.232241  0.027836 -0.025965  0.036613   \n",
       "...         ...       ...  ...       ...       ...       ...       ...   \n",
       "50787  0.682006  0.029171  ... -0.244216  0.053853 -0.008725 -0.048169   \n",
       "50788 -0.165982 -0.467275  ... -0.234947  0.049924  0.064670  0.022008   \n",
       "50789 -0.042930  0.201579  ... -0.234416 -0.001098 -0.035648 -0.053637   \n",
       "50790 -0.372697  0.197727  ... -0.247672  0.049712  0.028656 -0.078167   \n",
       "50791 -0.299033  0.236128  ... -0.244397  0.040046  0.010388 -0.072232   \n",
       "\n",
       "           V294      V295      V296      V297      V298      V299  \n",
       "0      0.027079 -0.100620  0.032597 -0.092093  0.048542  0.109286  \n",
       "1      0.029685 -0.110353  0.025347 -0.084554  0.045670  0.105747  \n",
       "2      0.018669 -0.056828 -0.052640 -0.169819 -0.033054  0.053817  \n",
       "3     -0.119434 -0.074786 -0.072007 -0.049933  0.014863  0.063664  \n",
       "4     -0.087056 -0.103006  0.076729 -0.153311  0.038894  0.138866  \n",
       "...         ...       ...       ...       ...       ...       ...  \n",
       "50787 -0.032766 -0.062842 -0.059161 -0.104091  0.010547  0.129130  \n",
       "50788  0.025572 -0.144732 -0.046366 -0.030195 -0.027131  0.093039  \n",
       "50789  0.030076 -0.037331  0.048593 -0.019262 -0.030251  0.178724  \n",
       "50790  0.047243  0.061589  0.016127 -0.073754 -0.011532  0.154577  \n",
       "50791  0.047836  0.046529  0.009858 -0.067272 -0.009805  0.183828  \n",
       "\n",
       "[50792 rows x 371 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"embeddings.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, each row represents a different news article and is associated with one of the top 15 stocks that we are interested in for our classifier: <br>\n",
    "`['AAPL', 'AMZN', 'BA', 'BCS', 'BP', 'C', 'DB', 'GM', 'GS', 'HSEA', 'HSEB', 'JPM', 'MSFT', 'MS', 'TAPR']`.\n",
    "\n",
    "Additionally, the columns `[K0, ..., K63]` represent the components of the $K_i^{(t)}$ embedding vector and the columns `[V0, ..., V299]` represent the components of the $V_i^{(t)}$ embedding vector for each article $n_i^{(t)}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing our Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Bi-GRU price movement classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6674"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## do it for one stock, AAPL\n",
    "aapl = data[data['Ticker'] == 'AAPL']\n",
    "len(aapl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## set kappa to be max number of articles for a given day\n",
    "kappa = np.max(aapl.groupby('Date').count()['index'])\n",
    "kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## remove dates that have < 4 articles, i.e. kappa = 4\n",
    "drop_dates = set(aapl['Date'].unique()[(aapl.groupby('Date').count()['index'] < 4)])\n",
    "drop_indices = [not aapl['Date'][i] in drop_dates for i in range(len(aapl))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## now all dates have 4 <= i < 12 articles\n",
    "aapl_processed = aapl[drop_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "792"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_dates  = sorted(aapl_processed['Date'].unique())\n",
    "num_sequences = len(sorted_dates[4:])\n",
    "num_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(data.iloc[:3, data.columns.get_loc('K0') : data.columns.get_loc('K63') + 1]).T.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have processed our data to include only robust inputs, let's do a quick refresher of what your initial input to the neural network is supposed to look like, and what dimensions it will have. Our key vectors are  $K_i^{(t)} \\in \\mathbb{R}^{64}$, and we have at most $\\kappa$ articles per day, i.e. for any given day, the inputs are $ \\in $  $ \\mathbb{R}^{64 * \\kappa}$. Since our network uses five market vectors for predicting stock price movement on any given day, and we have $ k $ overall market vector sequences that we are considering, the dimensions of our input matrix (flattened) are $\\mathbb 64k * 5\\kappa$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_mat = np.zeros((64*num_sequences, 5*kappa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#iterate through rows, step size of 64 to account for size of key vectors\n",
    "for i in range(0, 64*num_sequences, 64): \n",
    "    dates = sorted_dates[i : i + 5]\n",
    "    \n",
    "    #counter to keep track of column index\n",
    "    counter = 0\n",
    "    for date in dates: \n",
    "        df = aapl_processed[aapl_processed['Date'] == date]\n",
    "        sub_mat = np.array(df.iloc[:, df.columns.get_loc('K0') : df.columns.get_loc('K63') + 1]).T\n",
    "        input_mat[i : i + 64, counter : counter + sub_mat.shape[1]] = sub_mat\n",
    "        \n",
    "        #increment by kappa to go to next day in sequence\n",
    "        counter += kappa\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50688"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "64*num_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50688, 60)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_mat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def custom_sum(x):\n",
    "    linear_sum = []\n",
    "    alpha_weights = x[:kappa]\n",
    "    value_vecs = np.array(x[kappa:])\n",
    "    \n",
    "    value_vecs = value_vecs.reshape(300, kappa)\n",
    "    \n",
    "    for i in range(alpha_weights): \n",
    "        linear_sum += alpha_weights[i] * value_vecs[:, i]\n",
    "        \n",
    "    return linear_sum\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Activation, Input, Dense, GRU, Bidirectional\n",
    "from keras.models import Model\n",
    "from keras.layers.merge import Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Input(shape = input_mat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for i in range(num_sequences*5): \n",
    "    scores.append(Dense(kappa)(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = [Activation('softmax')(x) for x in scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 13)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Shape (3900, 1) must have rank 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-b5b18c6ea6f2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0malphas_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0malphas\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0minp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malphas_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue_vecs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;31m#need to check how to pass multiple inputs into Dense layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\varun jadia\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\varun jadia\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36mconcat\u001b[1;34m(values, axis, name)\u001b[0m\n\u001b[0;32m   1648\u001b[0m     \u001b[1;31m# TODO(keveman): Implement a standalone type and shape checker.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1649\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mscope\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1650\u001b[1;33m       ops.convert_to_tensor(\n\u001b[0m\u001b[0;32m   1651\u001b[0m           \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"concat_dim\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1652\u001b[0m           dtype=dtypes.int32).get_shape().assert_has_rank(0)\n",
      "\u001b[1;32mc:\\users\\varun jadia\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py\u001b[0m in \u001b[0;36massert_has_rank\u001b[1;34m(self, rank)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     \"\"\"\n\u001b[0;32m   1013\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrank\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1014\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Shape %s must have rank %d\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1015\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1016\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mwith_rank\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Shape (3900, 1) must have rank 0"
     ]
    }
   ],
   "source": [
    "linear_sums = []\n",
    "for i in range(num_sequences*5): \n",
    "    df = aapl_processed.loc[i:i+kappa, :]\n",
    "    value_vecs = np.array(df.iloc[:, df.columns.get_loc('V0') : df.columns.get_loc('V299') + 1]).T\n",
    "    print(value_vecs.shape)\n",
    "    value_vecs = value_vecs.reshape(value_vecs.shape[0] * value_vecs.shape[1], 1)\n",
    "    \n",
    "    alphas_arr = alphas[i]\n",
    "    \n",
    "    inp = tf.concat(alphas_arr, value_vecs) \n",
    "    print(inp.shape)\n",
    "    #need to check how to pass multiple inputs into Dense layer\n",
    "    linear_sums.append(Activation(custom_sum)(inp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_alphas = Concatenate([linear_sums[i] for i in range(len(linear_sums))])\n",
    "bigru = Bidirectional(GRU(num_sequences, activation = 'relu'))(flattened_alphas)\n",
    "pred = Dense(num_sequences, activation = 'sigmoid')(bigru)\n",
    "\n",
    "model = Model(inputs = x, outputs = pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
